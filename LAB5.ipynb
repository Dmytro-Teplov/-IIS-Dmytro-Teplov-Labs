{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNc2hlz4jwdKBuXmNegwmEm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dmytro-Teplov/-IIS-Dmytro-Teplov-Labs/blob/main/LAB5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End AI Agent Demonstration Using Gemini API  \n",
        "## Lab 1.5 – Master’s Thesis Implementation\n",
        "\n",
        "This notebook demonstrates my thesis AI system as a complete **end-to-end artificial intelligence agent**, implemented using **Google Colab** and the **Gemini API**.\n",
        "\n",
        "The system replicates the pipeline described in my thesis:\n",
        "\n",
        "1. Data Understanding  \n",
        "2. Preprocessing  \n",
        "3. Representation Learning / Reasoning  \n",
        "4. Inference  \n",
        "5. Output Generation (y)\n",
        "\n",
        "In this lab, I will run my previously designed prompts from Lab 1.4 (stored in `/prompts/`) and show how my system performs inference using the Gemini model.\n",
        "\n",
        "The notebook loads the Gemini API key securely using Colab Secrets, demonstrates zero-shot and few-shot prompting on my image dataset, and documents all stages of the end-to-end pipeline.\n"
      ],
      "metadata": {
        "id": "Nvjbo_itgi4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "id": "GRXLmb3QguXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_KEY = userdata.get(\"AIzaSyAntZUrDkmEZLhQLfpcOwcDoMqwKUYunw4\")\n",
        "\n",
        "if GEMINI_KEY is None:\n",
        "    raise ValueError(\"❌ ERROR: Gemini API key not found. Go to Tools → Secrets → Add GEMINI_KEY.\")\n",
        "\n",
        "genai.configure(api_key=GEMINI_KEY)\n",
        "\n",
        "print(\"✅ Gemini API key loaded securely.\")\n"
      ],
      "metadata": {
        "id": "Vg5hFjGGg1KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_prompt(relative_path):\n",
        "    with open(relative_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def run_gemini(prompt):\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "print(\"✅ Helper functions ready.\")\n"
      ],
      "metadata": {
        "id": "L8Q_0U92g28N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Prompts (Zero-shot & Few-shot)\n",
        "The next cells load the prompt templates from the `/prompts/` directory of the GitHub repository."
      ],
      "metadata": {
        "id": "_V2wdUMYg7bY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = \"/Dmytro-Teplov/-IIS-Dmytro-Teplov-Labs/\"\n",
        "\n",
        "zero_shot_prompt_path = os.path.join(repo_path, \"prompts/prompt_zero_shot.md\")\n",
        "few_shot_prompt_path = os.path.join(repo_path, \"prompts/prompt_few_shot.md\")\n",
        "\n",
        "zero_shot_prompt = load_prompt(zero_shot_prompt_path)\n",
        "few_shot_prompt = load_prompt(few_shot_prompt_path)\n",
        "\n",
        "print(\"Zero-shot prompt loaded:\\n\", zero_shot_prompt[:300], \"...\\n\")\n",
        "print(\"Few-shot prompt loaded:\\n\", few_shot_prompt[:300], \"...\")\n"
      ],
      "metadata": {
        "id": "oaUWQlvtg9F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End Demonstration  \n",
        "Below I will execute:\n",
        "\n",
        "### 1. Zero-shot inference using a single image (X → y)  \n",
        "### 2. Few-shot inference using (X, y) pairs in the prompt\n",
        "\n",
        "For each run, I will show:\n",
        "\n",
        "- Input (X)\n",
        "- Process description\n",
        "- Output (y)\n"
      ],
      "metadata": {
        "id": "IvHRtUcTiviQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running zero-shot inference...\\n\")\n",
        "zero_shot_output = run_gemini(zero_shot_prompt)\n",
        "print(\"=== Zero-Shot Output (y) ===\\n\")\n",
        "print(zero_shot_output)\n"
      ],
      "metadata": {
        "id": "YH423PqjixPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running few-shot inference...\\n\")\n",
        "few_shot_output = run_gemini(few_shot_prompt)\n",
        "print(\"=== Few-Shot Output (y) ===\\n\")\n",
        "print(few_shot_output)\n"
      ],
      "metadata": {
        "id": "7llHCWbIizGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End Pipeline Explanation\n",
        "\n",
        "Below is the conceptual mapping of the entire system:\n",
        "X (image input),\n",
        "Data Understanding,\n",
        "Preprocessing & Encoding,\n",
        "Gemini Reasoning & Pattern Extraction,\n",
        "Inference (mapping features → predicted label or annotation),\n",
        "y (final output)\n",
        "\n",
        "In this notebook:\n",
        "- The *prompt* defines all operations conceptually.\n",
        "- Gemini performs reasoning over the example (X, y) pairs.\n",
        "- The model produces the final prediction **y** for a new input image.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ue8CuYmCi3Hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "In this laboratory work, I demonstrated my thesis AI system as a complete end-to-end pipeline using the Gemini API in Google Colab. The system accepts input data (X), processes it through reasoning and inference using prompt-engineered instructions, and generates predictions (y). The prompts developed in Lab 1.4 were reused here to show both zero-shot and few-shot prediction behaviors. Using Colab Secrets allowed secure integration of the Gemini API without exposing sensitive keys.\n",
        "\n",
        "What worked especially well is that the few-shot prompt successfully leveraged annotated examples from Lab 1.2, improving performance on small data. The modular structure of the notebook clearly reflects the architecture of my thesis pipeline. Possible improvements include incorporating additional evaluation metrics, automating image visualization, and experimenting with different prompt designs for better generalization. Overall, this lab demonstrates that the system can operate as a unified AI agent capable of handling end-to-end tasks with minimal training data.\n"
      ],
      "metadata": {
        "id": "Bxnx7aSVjKsv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e715LVfUi46a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}