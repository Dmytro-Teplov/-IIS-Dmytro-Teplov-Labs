{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKvefmocMNLbLPSL0W7Nwz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dmytro-Teplov/-IIS-Dmytro-Teplov-Labs/blob/main/LAB5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End AI Agent Demonstration Using Gemini API  \n",
        "## Lab 1.5 – Master’s Thesis Implementation\n",
        "\n",
        "This notebook demonstrates my thesis AI system as a complete **end-to-end artificial intelligence agent**, implemented using **Google Colab** and the **Gemini API**.\n",
        "\n",
        "The system replicates the pipeline described in my thesis:\n",
        "\n",
        "1. Data Understanding  \n",
        "2. Preprocessing  \n",
        "3. Representation Learning / Reasoning  \n",
        "4. Inference  \n",
        "5. Output Generation (y)\n",
        "\n",
        "In this lab, I will run my previously designed prompts from Lab 1.4 (stored in `/prompts/`) and show how my system performs inference using the Gemini model.\n",
        "\n",
        "The notebook loads the Gemini API key securely using Colab Secrets, demonstrates zero-shot and few-shot prompting on my image dataset, and documents all stages of the end-to-end pipeline.\n"
      ],
      "metadata": {
        "id": "Nvjbo_itgi4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRXLmb3QguXf",
        "outputId": "f6c2ef9b-15b7-405b-c4ba-6ec095264a37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load API key securely from Colab → Tools → Secrets\n",
        "GEMINI_KEY = userdata.get(\"GEMINI_KEY\")\n",
        "\n",
        "if GEMINI_KEY is None:\n",
        "    raise ValueError(\"❌ ERROR: Gemini API key not found. Go to Tools → Secrets → Add GEMINI_KEY.\")\n",
        "\n",
        "genai.configure(api_key=GEMINI_KEY)\n",
        "\n",
        "print(\"✅ Gemini API key loaded securely.\")\n"
      ],
      "metadata": {
        "id": "Vg5hFjGGg1KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_prompt(relative_path):\n",
        "    with open(relative_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def run_gemini(prompt):\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "print(\"✅ Helper functions ready.\")\n"
      ],
      "metadata": {
        "id": "L8Q_0U92g28N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Prompts (Zero-shot & Few-shot)\n",
        "The next cells load the prompt templates from the `/prompts/` directory of the GitHub repository."
      ],
      "metadata": {
        "id": "_V2wdUMYg7bY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = \"/content/your-repo-name\"  # Change to correct repo directory if needed\n",
        "\n",
        "zero_shot_prompt_path = os.path.join(repo_path, \"prompts/prompt_zero_shot.md\")\n",
        "few_shot_prompt_path = os.path.join(repo_path, \"prompts/prompt_few_shot.md\")\n",
        "\n",
        "zero_shot_prompt = load_prompt(zero_shot_prompt_path)\n",
        "few_shot_prompt = load_prompt(few_shot_prompt_path)\n",
        "\n",
        "print(\"Zero-shot prompt loaded:\\n\", zero_shot_prompt[:300], \"...\\n\")\n",
        "print(\"Few-shot prompt loaded:\\n\", few_shot_prompt[:300], \"...\")\n"
      ],
      "metadata": {
        "id": "oaUWQlvtg9F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End Demonstration  \n",
        "Below I will execute:\n",
        "\n",
        "### 1. Zero-shot inference using a single image (X → y)  \n",
        "### 2. Few-shot inference using (X, y) pairs in the prompt\n",
        "\n",
        "For each run, I will show:\n",
        "\n",
        "- Input (X)\n",
        "- Process description\n",
        "- Output (y)\n"
      ],
      "metadata": {
        "id": "IvHRtUcTiviQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running zero-shot inference...\\n\")\n",
        "zero_shot_output = run_gemini(zero_shot_prompt)\n",
        "print(\"=== Zero-Shot Output (y) ===\\n\")\n",
        "print(zero_shot_output)\n"
      ],
      "metadata": {
        "id": "YH423PqjixPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running few-shot inference...\\n\")\n",
        "few_shot_output = run_gemini(few_shot_prompt)\n",
        "print(\"=== Few-Shot Output (y) ===\\n\")\n",
        "print(few_shot_output)\n"
      ],
      "metadata": {
        "id": "7llHCWbIizGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End Pipeline Explanation\n",
        "\n",
        "Below is the conceptual mapping of the entire system:\n",
        "X (image input),\n",
        "Data Understanding,\n",
        "Preprocessing & Encoding,\n",
        "Gemini Reasoning & Pattern Extraction,\n",
        "Inference (mapping features → predicted label or annotation),\n",
        "y (final output)\n",
        "\n",
        "In this notebook:\n",
        "- The *prompt* defines all operations conceptually.\n",
        "- Gemini performs reasoning over the example (X, y) pairs.\n",
        "- The model produces the final prediction **y** for a new input image.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ue8CuYmCi3Hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "In this laboratory work, I demonstrated my thesis AI system as a complete end-to-end pipeline using the Gemini API in Google Colab. The system accepts input data (X), processes it through reasoning and inference using prompt-engineered instructions, and generates predictions (y). The prompts developed in Lab 1.4 were reused here to show both zero-shot and few-shot prediction behaviors. Using Colab Secrets allowed secure integration of the Gemini API without exposing sensitive keys.\n",
        "\n",
        "What worked especially well is that the few-shot prompt successfully leveraged annotated examples from Lab 1.2, improving performance on small data. The modular structure of the notebook clearly reflects the architecture of my thesis pipeline. Possible improvements include incorporating additional evaluation metrics, automating image visualization, and experimenting with different prompt designs for better generalization. Overall, this lab demonstrates that the system can operate as a unified AI agent capable of handling end-to-end tasks with minimal training data.\n"
      ],
      "metadata": {
        "id": "Bxnx7aSVjKsv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e715LVfUi46a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}